{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create features from reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load restaurant reviews with hygyene-note\n",
    "reviews_file = \"./data/base_DFG_note\"\n",
    "reviews = pd.read_csv(reviews_file + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adresse</th>\n",
       "      <th>Code Postal</th>\n",
       "      <th>Commentaire</th>\n",
       "      <th>Date du commentaire</th>\n",
       "      <th>Note</th>\n",
       "      <th>Origine</th>\n",
       "      <th>Resto</th>\n",
       "      <th>Ville</th>\n",
       "      <th>Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Note_hyg</th>\n",
       "      <th>Note_resto</th>\n",
       "      <th>Note_hygiène_resto</th>\n",
       "      <th>Variance_note_resto</th>\n",
       "      <th>Variance_note_hygiène_resto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63 AV MOZART</td>\n",
       "      <td>75016</td>\n",
       "      <td>Un accueil hyper chaleureux! Les gérants sont ...</td>\n",
       "      <td>30/04/2016</td>\n",
       "      <td>5</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>macis cafe</td>\n",
       "      <td>Paris</td>\n",
       "      <td>0</td>\n",
       "      <td>20160430.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63 AV MOZART</td>\n",
       "      <td>75016</td>\n",
       "      <td>Nous cherchions à déjeuner, seul bémol, l'heur...</td>\n",
       "      <td>21/04/2016</td>\n",
       "      <td>4</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>macis cafe</td>\n",
       "      <td>Paris</td>\n",
       "      <td>1</td>\n",
       "      <td>20160421.0</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63 AV MOZART</td>\n",
       "      <td>75016</td>\n",
       "      <td>Des plats réalisés à partir de produits frais ...</td>\n",
       "      <td>10/02/2016</td>\n",
       "      <td>3</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>macis cafe</td>\n",
       "      <td>Paris</td>\n",
       "      <td>2</td>\n",
       "      <td>20160210.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90 Rue des Orteaux</td>\n",
       "      <td>75020</td>\n",
       "      <td>Restaurant Sushi plutot correct dans l ensembl...</td>\n",
       "      <td>27/02/2016</td>\n",
       "      <td>3</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>sushi tomi</td>\n",
       "      <td>Paris</td>\n",
       "      <td>3</td>\n",
       "      <td>20160227.0</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.866667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90 Rue des Orteaux</td>\n",
       "      <td>75020</td>\n",
       "      <td>Déçue de ma dernière visite car impossible de ...</td>\n",
       "      <td>17/01/2016</td>\n",
       "      <td>3</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>sushi tomi</td>\n",
       "      <td>Paris</td>\n",
       "      <td>4</td>\n",
       "      <td>20160117.0</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.866667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Adresse Code Postal  \\\n",
       "0        63 AV MOZART       75016   \n",
       "1        63 AV MOZART       75016   \n",
       "2        63 AV MOZART       75016   \n",
       "3  90 Rue des Orteaux       75020   \n",
       "4  90 Rue des Orteaux       75020   \n",
       "\n",
       "                                         Commentaire Date du commentaire  \\\n",
       "0  Un accueil hyper chaleureux! Les gérants sont ...          30/04/2016   \n",
       "1  Nous cherchions à déjeuner, seul bémol, l'heur...          21/04/2016   \n",
       "2  Des plats réalisés à partir de produits frais ...          10/02/2016   \n",
       "3  Restaurant Sushi plutot correct dans l ensembl...          27/02/2016   \n",
       "4  Déçue de ma dernière visite car impossible de ...          17/01/2016   \n",
       "\n",
       "   Note      Origine       Resto  Ville  Id        Date  Note_hyg  Note_resto  \\\n",
       "0     5  TripAdvisor  macis cafe  Paris   0  20160430.0  5.000000         4.0   \n",
       "1     4  TripAdvisor  macis cafe  Paris   1  20160421.0  4.800000         4.0   \n",
       "2     3  TripAdvisor  macis cafe  Paris   2  20160210.0  5.000000         4.0   \n",
       "3     3  TripAdvisor  sushi tomi  Paris   3  20160227.0  4.833333         3.0   \n",
       "4     3  TripAdvisor  sushi tomi  Paris   4  20160117.0  4.900000         3.0   \n",
       "\n",
       "   Note_hygiène_resto  Variance_note_resto  Variance_note_hygiène_resto  \n",
       "0            4.800000             0.666667                     0.000000  \n",
       "1            4.800000             0.666667                     0.000000  \n",
       "2            4.800000             0.666667                     0.000000  \n",
       "3            4.866667             0.000000                     0.001111  \n",
       "4            4.866667             0.000000                     0.001111  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['16', 'alimentair', 'assaison', 'attend', 'brul', 'canap', 'cher', 'commissariat', 'comprenon', 'courent', 'cri', 'cru', 'cuisin', 'désoblig', 'except', 'fraich', 'gaufr', 'gav', 'glu', 'gu', 'haw', 'horribl', 'indigest', 'infect', 'intox', 'lac', 'lendemain', 'loc', 'malad', 'marn', 'miush', 'nantu', 'nor', 'nuit', 'oblig', 'oreil', 'pert', 'plas', 'poivr', 'pompon', 'potag', 'poubel', 'propos', 'pulper', 'pékinois', 'remarqu', 'retiendr', 'réfrig', 'scandal', 'sept', 'sourd', 'tomb', 'traversent', 'ventr', 'vom', 'écrev', 'épic', 'éton']\n",
      "Vocabulary length:  58\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer + stemmer\n",
    "\n",
    "# based on http://www.cs.duke.edu/courses/spring14/compsci290/assignments/lab02.html\n",
    "stemmer = SnowballStemmer(\"french\")\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems\n",
    "\n",
    "vocab = 'poivre loc ventre obligé malade réfrigérateur nori assaisonnées proposé pompon écrevisse gaufres lac nantua criant intoxication lendemain sept scandaleux épicée vomi pulperia sourd infectes fraiches courent horribles marnière exception indigestion malades oreille gluante guère comprenons étonnant 16 chères cru attendaient miushi tombées hawai perte cuisiniers nuits désobligeantes commissariat remarques plas poubelle gave retiendra alimentaire gluant traversent pékinois potage canapés brulé'\n",
    "vocab_stem = tokenize(vocab)\n",
    "hyg_dictionary = {}\n",
    "idx = 0\n",
    "for i in range(len(vocab_stem)):\n",
    "    if vocab_stem[i] != \"\":\n",
    "        hyg_dictionary[vocab_stem[i]] = idx\n",
    "        # print(i,vocab_stem[i])\n",
    "        idx += 1\n",
    "\n",
    "vect = CountVectorizer(tokenizer=tokenize)\n",
    "vect.fit(vocab_stem)\n",
    "vocabulary = vect.get_feature_names()\n",
    "print('Vocabulary: %s' %vocabulary)\n",
    "print(\"Vocabulary length: \", len(vect.get_feature_names()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adresse</th>\n",
       "      <th>Code Postal</th>\n",
       "      <th>Resto</th>\n",
       "      <th>Ville</th>\n",
       "      <th>Note_resto</th>\n",
       "      <th>Note_hygiène_resto</th>\n",
       "      <th>Variance_note_resto</th>\n",
       "      <th>Variance_note_hygiène_resto</th>\n",
       "      <th>16</th>\n",
       "      <th>alimentair</th>\n",
       "      <th>...</th>\n",
       "      <th>sept</th>\n",
       "      <th>sourd</th>\n",
       "      <th>tomb</th>\n",
       "      <th>traversent</th>\n",
       "      <th>ventr</th>\n",
       "      <th>vom</th>\n",
       "      <th>écrev</th>\n",
       "      <th>épic</th>\n",
       "      <th>éton</th>\n",
       "      <th>rev_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Adresse, Code Postal, Resto, Ville, Note_resto, Note_hygiène_resto, Variance_note_resto, Variance_note_hygiène_resto, 16, alimentair, assaison, attend, brul, canap, cher, commissariat, comprenon, courent, cri, cru, cuisin, désoblig, except, fraich, gaufr, gav, glu, gu, haw, horribl, indigest, infect, intox, lac, lendemain, loc, malad, marn, miush, nantu, nor, nuit, oblig, oreil, pert, plas, poivr, pompon, potag, poubel, propos, pulper, pékinois, remarqu, retiendr, réfrig, scandal, sept, sourd, tomb, traversent, ventr, vom, écrev, épic, éton, rev_cnt]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 67 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empty DataFrame where features will be stored\n",
    "rev_cols = ['Adresse', 'Code Postal', 'Resto', 'Ville', 'Note_resto',\n",
    "       'Note_hygiène_resto', 'Variance_note_resto',\n",
    "       'Variance_note_hygiène_resto']\n",
    "cols = rev_cols + vocabulary + [\"rev_cnt\"]\n",
    "features = pd.DataFrame([], columns=cols)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adresse</th>\n",
       "      <th>Code Postal</th>\n",
       "      <th>Resto</th>\n",
       "      <th>Ville</th>\n",
       "      <th>Note_resto</th>\n",
       "      <th>Note_hygiène_resto</th>\n",
       "      <th>Variance_note_resto</th>\n",
       "      <th>Variance_note_hygiène_resto</th>\n",
       "      <th>16</th>\n",
       "      <th>alimentair</th>\n",
       "      <th>...</th>\n",
       "      <th>sept</th>\n",
       "      <th>sourd</th>\n",
       "      <th>tomb</th>\n",
       "      <th>traversent</th>\n",
       "      <th>ventr</th>\n",
       "      <th>vom</th>\n",
       "      <th>écrev</th>\n",
       "      <th>épic</th>\n",
       "      <th>éton</th>\n",
       "      <th>rev_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55 Boulevard Saint Marcel</td>\n",
       "      <td>75013</td>\n",
       "      <td>0 d'attente</td>\n",
       "      <td>Paris</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>2.269600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128, rue du Faubourg Saint Martin</td>\n",
       "      <td>75010</td>\n",
       "      <td>0039 ristorante italiano</td>\n",
       "      <td>Paris</td>\n",
       "      <td>3.222222</td>\n",
       "      <td>4.846111</td>\n",
       "      <td>2.172840</td>\n",
       "      <td>0.020053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60 rue Albert</td>\n",
       "      <td>75013</td>\n",
       "      <td>015 gang nam</td>\n",
       "      <td>Paris</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.844444</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.010617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>161 Avenue D'Italie</td>\n",
       "      <td>75013</td>\n",
       "      <td>1 pot</td>\n",
       "      <td>Paris</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.916667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55 Boulevard Saint Marcel</td>\n",
       "      <td>75013</td>\n",
       "      <td>0 d'attente</td>\n",
       "      <td>Paris</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>2.269600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Adresse Code Postal                     Resto  \\\n",
       "0          55 Boulevard Saint Marcel       75013               0 d'attente   \n",
       "1  128, rue du Faubourg Saint Martin       75010  0039 ristorante italiano   \n",
       "2                      60 rue Albert       75013              015 gang nam   \n",
       "3                161 Avenue D'Italie       75013                     1 pot   \n",
       "4          55 Boulevard Saint Marcel       75013               0 d'attente   \n",
       "\n",
       "   Ville  Note_resto  Note_hygiène_resto  Variance_note_resto  \\\n",
       "0  Paris    3.900000            3.670000             0.290000   \n",
       "1  Paris    3.222222            4.846111             2.172840   \n",
       "2  Paris    4.333333            4.844444             0.222222   \n",
       "3  Paris    4.000000            4.916667             0.666667   \n",
       "4  Paris    3.900000            3.670000             0.290000   \n",
       "\n",
       "   Variance_note_hygiène_resto   16  alimentair   ...     sept  sourd  tomb  \\\n",
       "0                     2.269600  0.0         0.0   ...      0.0    0.0   0.0   \n",
       "1                     0.020053  0.0         0.0   ...      0.0    0.0   0.0   \n",
       "2                     0.010617  0.0         0.0   ...      0.0    0.0   0.0   \n",
       "3                     0.000278  0.0         0.0   ...      0.0    0.0   0.0   \n",
       "4                     2.269600  0.0         0.0   ...      0.0    0.0   0.0   \n",
       "\n",
       "   traversent  ventr  vom  écrev  épic  éton  rev_cnt  \n",
       "0         0.0    0.0  0.0    0.0   3.0   1.0     10.0  \n",
       "1         0.0    0.0  0.0    0.0   0.0   0.0      9.0  \n",
       "2         0.0    0.0  0.0    0.0   0.0   0.0      6.0  \n",
       "3         0.0    0.0  0.0    0.0   0.0   0.0      6.0  \n",
       "4         0.0    0.0  0.0    0.0   3.0   1.0     10.0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "for (resto, adresse), grp in reviews.groupby([\"Resto\", \"Adresse\"]):\n",
    "    subset = reviews[(reviews[\"Resto\"] == resto) & (reviews[\"Adresse\"] == adresse)]\n",
    "    reviews_cnt = subset.shape[0]\n",
    "    merged_reviews = subset[\"Commentaire\"].str.cat(sep=' ')\n",
    "    \n",
    "    if idx <= reviews.shape[0]:\n",
    "        # Count words \n",
    "        rev_vect = vect.transform([merged_reviews])\n",
    "        #print(resto, adresse)\n",
    "        #print(\"Number of reviews: \", reviews_cnt)\n",
    "        # print(subset.head())\n",
    "        #print(rev_vect)\n",
    "        #print('Vocabulary: %s' %vect.get_feature_names())\n",
    "        #print(\"Length of merged review\", len(merged_reviews))\n",
    "        #print('Merged review:', merged_reviews)\n",
    "        #print('Merged review vector:', rev_vect.toarray())\n",
    "        # Original data that we will keep\n",
    "        #print(subset[rev_cols])\n",
    "        # Generated features\n",
    "        countvec_df = pd.DataFrame(rev_vect.toarray(), columns=[vocabulary])\n",
    "        merged_df = pd.DataFrame([], columns=cols)\n",
    "        merged_df[rev_cols] = subset[rev_cols].head(1)\n",
    "        merged_df.reset_index(drop=True, inplace=True)\n",
    "        merged_df[vocabulary] = countvec_df[vocabulary].head(1)\n",
    "        merged_df.reset_index(drop=True, inplace=True)\n",
    "        merged_df[\"rev_cnt\"] = reviews_cnt\n",
    "        #print(merged_df.head())\n",
    "        features = features.append(merged_df, ignore_index=True)\n",
    "        del(merged_df)\n",
    "    else:\n",
    "        break\n",
    "    idx += 1\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9665, 67)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save features\n",
    "features_file = reviews_file + '_feat.csv'\n",
    "features.to_csv(features_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.5 env",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
